{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a982fc-8060-40bc-88a3-5ef5a888303c",
   "metadata": {},
   "source": [
    "# Deepfake and Real Audio Detection System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4510b-d5ff-496d-b6af-52ed8f3d8fff",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "The data is already split up in to training, validation and test sets, which contains folders of fake and real\n",
    "Each sample is a 2 second clip, balanced in terms of gender and class.\n",
    "Data is also normalised in terms of sample rate, volume and number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b14ebc2-2467-4c99-905b-714fad9fbd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 06:20:57.011580: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747635657.024996     250 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747635657.029177     250 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_data_from_folder(base_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      base_path: root folder containing subfolders 'training', 'validation', 'testing'\n",
    "    Returns:\n",
    "      dict with keys 'training','validation','testing', each a tuple\n",
    "      (features, labels, filenames) where:\n",
    "        - features: np.ndarray, shape (N, L), dtype float32\n",
    "        - labels:   np.ndarray, shape (N,),    dtype int32\n",
    "        - filenames: list of file paths\n",
    "    \"\"\"\n",
    "    target_length = int(16000 * 2.0)  # 2 seconds at 16kHz\n",
    "    label_map = {\"fake\": 0, \"real\": 1}\n",
    "    out = {}\n",
    "    for split in ['training', 'validation', 'testing']:\n",
    "        data, labels, files = [], [], []\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        for class_name in ['fake', 'real']:\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "            for fname in sorted(os.listdir(class_path)):\n",
    "                if not fname.endswith('.wav'):\n",
    "                    continue\n",
    "                path = os.path.join(class_path, fname)\n",
    "                # 1) load + resample\n",
    "                y, sr = librosa.load(path, sr=16000)  \n",
    "                \n",
    "                # Ensure all audio samples are the same length (pad or trim)\n",
    "                if len(y) > target_length:\n",
    "                    y = y[:target_length]\n",
    "                elif len(y) < target_length:\n",
    "                    y = np.pad(y, (0, target_length - len(y)), 'constant')\n",
    "                \n",
    "                data.append(y)\n",
    "                labels.append(label_map[class_name])\n",
    "                files.append(path)\n",
    "                \n",
    "        # stack into (N, L) shape, cast to float32\n",
    "        X = np.stack(data, axis=0).astype('float32')\n",
    "        y = np.array(labels, dtype='int32')\n",
    "        out[split] = (X, y, files)\n",
    "    return out\n",
    "\n",
    "def create_tf_datasets(data_dict, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create TensorFlow datasets from the loaded data dictionary.\n",
    "    Memory-efficient implementation that avoids OOM errors when dealing with large audio files.\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary with 'training', 'validation', 'testing' splits\n",
    "        batch_size: Batch size for the datasets\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with TensorFlow datasets for each split\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    for split in ['training', 'validation', 'testing']:\n",
    "        if split not in data_dict:\n",
    "            continue\n",
    "            \n",
    "        features, labels, _ = data_dict[split]\n",
    "        \n",
    "        # Convert to list of individual examples to avoid loading all data into memory at once\n",
    "        feature_list = [features[i] for i in range(len(features))]\n",
    "        label_list = [labels[i] for i in range(len(labels))]\n",
    "        \n",
    "        # Generator function to yield one sample at a time to avoid memory issues\n",
    "        def generator():\n",
    "            for i in range(len(feature_list)):\n",
    "                # Add channel dimension for RawNet (expects shape [None, 1])\n",
    "                yield feature_list[i][..., np.newaxis], label_list[i]\n",
    "        \n",
    "        # Get output shapes and types\n",
    "        output_shapes = (\n",
    "            tf.TensorShape([None, 1]),  # Variable length audio with 1 channel\n",
    "            tf.TensorShape([])          # Scalar label\n",
    "        )\n",
    "        output_types = (tf.float32, tf.int32)\n",
    "        \n",
    "        # Create dataset from generator\n",
    "        ds = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_types=output_types,\n",
    "            output_shapes=output_shapes\n",
    "        )\n",
    "        \n",
    "        # Apply dataset transformations\n",
    "        if split == 'training':\n",
    "            # Shuffle training data (with smaller buffer size to save memory)\n",
    "            buffer_size = min(len(feature_list), 1000)  # Limit buffer size\n",
    "            ds = ds.shuffle(buffer_size=buffer_size)\n",
    "            ds = ds.batch(batch_size)\n",
    "            ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "        else:\n",
    "            ds = ds.batch(batch_size)\n",
    "            ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "            \n",
    "        datasets[split] = ds\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e0adbf3-fcd3-4c6b-b617-83c5a39dedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"for-2seconds\"\n",
    "data = load_data_from_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76268f31-50ea-4fd1-b53b-0aeef0097549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data shapes before creating datasets\n",
    "training_features, training_labels, train_files = data['training']\n",
    "validation_features, validation_labels, val_files = data['validation']\n",
    "test_features, test_labels, test_files = data['testing']\n",
    "\n",
    "print(\"Train features shape:\", training_features.shape, training_features.dtype)\n",
    "print(\"Train labels shape:\", training_labels.shape, training_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e712d38a-9845-4a61-840c-d6b0047768bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch size: 32\n",
      "WARNING:tensorflow:From /tmp/ipykernel_250/1609594272.py:88: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /tmp/ipykernel_250/1609594272.py:88: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747635707.658564     250 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1880 MB memory:  -> device: 0, name: NVIDIA A16-4Q, pci bus id: 0000:02:0d.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: (32, 32000, 1)\n",
      "Label batch shape: (32,)\n",
      "Dataset creation successful!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "print(f\"Using batch size: {batch_size}\")\n",
    "\n",
    "# Create TensorFlow datasets with memory-efficient approach\n",
    "try:\n",
    "    datasets = create_tf_datasets(data, batch_size=batch_size)\n",
    "    \n",
    "    train_ds = datasets['training']\n",
    "    validation_ds = datasets['validation']\n",
    "    test_ds = datasets['testing']\n",
    "    \n",
    "    # Verify dataset shapes\n",
    "    for x, y in train_ds.take(1):\n",
    "        print(f\"Input batch shape: {x.shape}\")\n",
    "        print(f\"Label batch shape: {y.shape}\")\n",
    "        \n",
    "    print(\"Dataset creation successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating datasets: {e}\")\n",
    "    print(\"If you're still having memory issues, try further reducing batch_size or implementing dataset streaming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881284d8-fc7e-4771-a3bd-6becd8bc96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "def test_data_loader_with_spectrogram(data, sr=16000):\n",
    "    \"\"\"\n",
    "    Displays waveform and spectrogram for first and last samples in the training set.\n",
    "    - data: dict with 'training' → (features, labels, filenames)\n",
    "    - sr: sample rate (Hz) to use for time/frequency axes\n",
    "    \"\"\"\n",
    "    features, labels, files = data['training']\n",
    "    samples = [\n",
    "        (\"First\", features[0], labels[0]),\n",
    "        (\"Last\",  features[-1], labels[-1])\n",
    "    ]\n",
    "\n",
    "    for title, audio, label in samples:\n",
    "        # Time axis\n",
    "        duration = len(audio) / sr\n",
    "        t = np.linspace(0, duration, len(audio))\n",
    "\n",
    "        # 1) Waveform\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        plt.plot(t, audio, linewidth=0.8)\n",
    "        plt.title(f\"{title} Sample Waveform\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 2) Spectrogram\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        Pxx, freqs, bins, im = plt.specgram(\n",
    "            audio, NFFT=1024, Fs=sr, noverlap=512, cmap='viridis'\n",
    "        )\n",
    "        plt.title(f\"{title} Sample Spectrogram\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Frequency (Hz)\")\n",
    "        plt.colorbar(im).set_label('Intensity [dB]')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # 3) Playback\n",
    "        display(Audio(audio, rate=sr))\n",
    "\n",
    "# Example usage:\n",
    "test_data_loader_with_spectrogram(data, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1e3c84-ae63-4168-a418-1a413bc13bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13956, 32000) (13956,)\n",
      "(2826, 32000) (2826,)\n",
      "(1088, 32000) (1088,)\n"
     ]
    }
   ],
   "source": [
    "# Testing sizes\n",
    "print(training_features.shape, training_labels.shape) # Needs to be 13956\n",
    "print(validation_features.shape, validation_labels.shape) # Needs to be 2826\n",
    "print(test_features.shape, test_labels.shape) # Needs to be 1088\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d41a6-50e7-448a-b965-e215911cfde8",
   "metadata": {},
   "source": [
    "## Data Augmentation (Only-if you deem necessary) - If results show overfitting, add some augmentation\n",
    "Potentially adding some noise, pitch shifting, we have 7 hours of audio. Dont think augmentation would be necessary, so yea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e555900-e79e-4be3-8f19-af793c48d5e8",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Use your designated approach\n",
    "Use a Waveform based 1D CNN (research into CNN architectures that are used for noise recognition)\n",
    "Paper: https://arxiv.org/pdf/2004.00526\n",
    "Paper modifies the RawNet Model. We will implement some of the same modifications and tweak a few things of our own\n",
    "If possible, we could compare the two branched models from the RawNet on our data set and see what the differences in performance.\n",
    "\n",
    "The aim to to defer from the Original RawNet architecture, add slight adjustments and see \n",
    "\n",
    "1. But with this dataset we will use binary cross entropy instead of CCE\n",
    "2. We are using a different data set here. OG used VoxCeleb1, paper used VoxCeleb2'\n",
    "3. We will use a attention mechanism alongside GRU layer, (they created a self-attention layer to replace GRU layers)\n",
    "4. Lastly we will compare out EER to their EER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ccdaedb1-b20f-4319-bfa0-37a9677bbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"small_rawnet_reg\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"small_rawnet_reg\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_waveform      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │ input_waveform[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_168[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_128     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_initial        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ drop_initial[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_169[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_129     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> │ leaky_re_lu_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ drop_initial[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_170[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_171[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_130     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_172[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_131     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │ leaky_re_lu_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_173[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_174[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_132     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_132[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_down_conv      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ time_down_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_133     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_downsample     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidir_gru_seq       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │ drop_downsample[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,968</span> │ bidir_gru_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ bidir_gru_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ bidir_gru_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidir_gru_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ self_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attn_norm           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_attn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attn_norm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_pool           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ drop_attn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ time_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_waveform      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_168 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m48\u001b[0m │ input_waveform[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m64\u001b[0m │ conv1d_168[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_128     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_initial        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_128[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_169 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m1,536\u001b[0m │ drop_initial[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m128\u001b[0m │ conv1d_169[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_129     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_170 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │      \u001b[38;5;34m3,072\u001b[0m │ leaky_re_lu_129[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_171 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ drop_initial[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m128\u001b[0m │ conv1d_170[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m128\u001b[0m │ conv1d_171[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_70 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_130     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_130[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_172 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m6,144\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_172[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_131     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_173 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,288\u001b[0m │ leaky_re_lu_131[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_174 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m2,048\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_173[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv1d_174[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_71 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_132     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_132[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_down_conv      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m12,288\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ time_down_conv[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_133     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_downsample     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_133[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidir_gru_seq       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m49,920\u001b[0m │ drop_downsample[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m131,968\u001b[0m │ bidir_gru_seq[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ bidir_gru_seq[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ bidir_gru_seq[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_72 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ bidir_gru_seq[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ self_attention[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attn_norm           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ add_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ drop_attn (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ attn_norm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_pool           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ drop_attn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ time_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,681</span> (865.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221,681\u001b[0m (865.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220,945</span> (863.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m220,945\u001b[0m (863.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">736</span> (2.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m736\u001b[0m (2.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "def small_rawnet_reg(input_shape=(None, 1),\n",
    "                     gru_units=64,\n",
    "                     l2=1e-4,\n",
    "                     dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape, name=\"input_waveform\")\n",
    "\n",
    "    # 1) Initial Conv layer (fewer filters) + Dropout\n",
    "    x = layers.Conv1D(\n",
    "          16, 3, strides=2, padding='same', use_bias=False,\n",
    "          kernel_regularizer=regularizers.l2(l2)\n",
    "        )(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.3)(x)\n",
    "    x = layers.Dropout(dropout_rate, name=\"drop_initial\")(x)\n",
    "\n",
    "    # 2) Simple residual block (optional) + Dropout inside\n",
    "    def res_block(x, filters, stride=1):\n",
    "        shortcut = x\n",
    "        y = layers.Conv1D(\n",
    "              filters, 3, strides=stride, padding='same', use_bias=False,\n",
    "              kernel_regularizer=regularizers.l2(l2)\n",
    "            )(x)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "        y = layers.LeakyReLU(negative_slope=0.3)(y)\n",
    "\n",
    "        y = layers.Conv1D(\n",
    "              filters, 3, padding='same', use_bias=False,\n",
    "              kernel_regularizer=regularizers.l2(l2)\n",
    "            )(y)\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        if stride != 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = layers.Conv1D(\n",
    "                          filters, 1, strides=stride, use_bias=False,\n",
    "                          kernel_regularizer=regularizers.l2(l2)\n",
    "                       )(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = layers.Add()([y, shortcut])\n",
    "        y = layers.LeakyReLU(negative_slope=0.3)(y)\n",
    "        return layers.Dropout(dropout_rate)(y)\n",
    "\n",
    "    x = res_block(x, 32, stride=2)\n",
    "    x = res_block(x, 64, stride=2)\n",
    "\n",
    "    # 3) Time downsampling conv + Dropout\n",
    "    x = layers.Conv1D(\n",
    "          64, 3, strides=8, padding=\"same\", use_bias=False,\n",
    "          kernel_regularizer=regularizers.l2(l2),\n",
    "          name=\"time_down_conv\"\n",
    "        )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.3)(x)\n",
    "    x = layers.Dropout(dropout_rate, name=\"drop_downsample\")(x)\n",
    "\n",
    "    # 4) Bidirectional GRU with sequences, with recurrent dropout\n",
    "    x = layers.Bidirectional(\n",
    "          layers.GRU(\n",
    "            gru_units,\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=regularizers.l2(l2),\n",
    "            recurrent_regularizer=regularizers.l2(l2),\n",
    "            dropout=dropout_rate,\n",
    "            recurrent_dropout=dropout_rate\n",
    "          ),\n",
    "          name=\"bidir_gru_seq\"\n",
    "        )(x)\n",
    "\n",
    "    # 5) Multi-Head Self Attention + Dropout\n",
    "    attn_output = layers.MultiHeadAttention(\n",
    "                    num_heads=4,\n",
    "                    key_dim=64,\n",
    "                    kernel_regularizer=regularizers.l2(l2),\n",
    "                    name=\"self_attention\"\n",
    "                  )(query=x, value=x, key=x)\n",
    "    x = layers.Add()([x, attn_output])\n",
    "    x = layers.LayerNormalization(name=\"attn_norm\")(x)\n",
    "    x = layers.Dropout(dropout_rate, name=\"drop_attn\")(x)\n",
    "\n",
    "    # 6) Pool over time\n",
    "    x = layers.GlobalAveragePooling1D(name=\"time_pool\")(x)\n",
    "\n",
    "    # 7) Final Dense for binary output (with L2)\n",
    "    out = layers.Dense(\n",
    "            1,\n",
    "            activation='sigmoid',\n",
    "            kernel_regularizer=regularizers.l2(l2),\n",
    "            name='output'\n",
    "          )(x)\n",
    "\n",
    "    return models.Model(inputs, out, name='small_rawnet_reg')\n",
    "\n",
    "# Build and inspect\n",
    "small = small_rawnet_reg((None,1), gru_units=64)\n",
    "small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9474ea34-ee52-4d94-9603-cc6bec09eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import keras\n",
    "train_time = 20\n",
    "\n",
    "class TrainForTime(keras.callbacks.Callback):\n",
    "    \"\"\"callback to terminate training after a time limit is reached\n",
    "\n",
    "    Can be used to control how long training runs for, and will terminate\n",
    "    training once a specified time limit is reached.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_time_mins=15,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_time_mins = train_time_mins\n",
    "        self.epochs = 0\n",
    "        self.train_time = 0\n",
    "        self.end_early = False\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # save the start time\n",
    "        self.start_time = tf.timestamp()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epochs += 1\n",
    "        current_time = tf.timestamp()\n",
    "        training_time = (current_time - self.start_time)\n",
    "        if (training_time / 60) > self.train_time_mins:\n",
    "            self.train_time = current_time - self.start_time\n",
    "            self.model.stop_training = True\n",
    "            self.end_early = True\n",
    "\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.end_early:\n",
    "            print('training time exceeded and ending early')\n",
    "            print(f'training ended on epoch {self.epochs}')\n",
    "            print(f'training time = {self.train_time / 60} mins')\n",
    "\n",
    "# Set up the EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitor the validation loss\n",
    "    patience=10,              # Stop after 10 epochs of no improvement\n",
    "    mode='min',               # 'min' means the training will stop when the val_loss stops decreasing\n",
    "    verbose=1,                # Print a message when training stops\n",
    "    restore_best_weights=True # Restore the best model weights when training stops\n",
    ")\n",
    "\n",
    "# Set up the ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model_attn_dropouts.keras',                # Path where the model will be saved\n",
    "    monitor='val_loss',             # Monitor validation loss (can also use 'val_accuracy')\n",
    "    save_best_only=True,            # Only save the model if it improves\n",
    "    mode='min',                     # 'min' means the model with the minimum validation loss will be saved\n",
    "    verbose=1                        # Prints out when the model is saved\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    filepath='model_attn_epoch_{epoch:02d}.keras',  # include epoch in filename\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,     # save every epoch, not only the best\n",
    "    mode='auto',              # 'auto' will infer min/max from the monitored metric\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28263efd-b28d-421e-9079-0690c178d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "     34/Unknown \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.6017 - loss: 0.7595\n",
      "Epoch 1: val_loss improved from inf to 2.44685, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step - accuracy: 0.6037 - loss: 0.7573 - val_accuracy: 0.5000 - val_loss: 2.4468\n",
      "Epoch 2/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7895 - loss: 0.5239\n",
      "Epoch 2: val_loss did not improve from 2.44685\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.7905 - loss: 0.5224 - val_accuracy: 0.5000 - val_loss: 3.3656\n",
      "Epoch 3/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8732 - loss: 0.3806\n",
      "Epoch 3: val_loss did not improve from 2.44685\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.8738 - loss: 0.3791 - val_accuracy: 0.5000 - val_loss: 5.1405\n",
      "Epoch 4/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8721 - loss: 0.3671\n",
      "Epoch 4: val_loss improved from 2.44685 to 2.41277, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8727 - loss: 0.3659 - val_accuracy: 0.5000 - val_loss: 2.4128\n",
      "Epoch 5/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9464 - loss: 0.2050\n",
      "Epoch 5: val_loss improved from 2.41277 to 1.30793, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9469 - loss: 0.2043 - val_accuracy: 0.4467 - val_loss: 1.3079\n",
      "Epoch 6/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9517 - loss: 0.2145\n",
      "Epoch 6: val_loss improved from 1.30793 to 1.16749, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9517 - loss: 0.2143 - val_accuracy: 0.4982 - val_loss: 1.1675\n",
      "Epoch 7/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9644 - loss: 0.1600\n",
      "Epoch 7: val_loss did not improve from 1.16749\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9644 - loss: 0.1597 - val_accuracy: 0.5570 - val_loss: 1.2426\n",
      "Epoch 8/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9780 - loss: 0.1245\n",
      "Epoch 8: val_loss did not improve from 1.16749\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9777 - loss: 0.1251 - val_accuracy: 0.5000 - val_loss: 3.0087\n",
      "Epoch 9/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9731 - loss: 0.1445\n",
      "Epoch 9: val_loss did not improve from 1.16749\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9733 - loss: 0.1438 - val_accuracy: 0.5000 - val_loss: 4.3200\n",
      "Epoch 10/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9855 - loss: 0.0958\n",
      "Epoch 10: val_loss improved from 1.16749 to 0.86650, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9854 - loss: 0.0962 - val_accuracy: 0.7794 - val_loss: 0.8665\n",
      "Epoch 11/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9841 - loss: 0.1027\n",
      "Epoch 11: val_loss did not improve from 0.86650\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9841 - loss: 0.1027 - val_accuracy: 0.6094 - val_loss: 2.2910\n",
      "Epoch 12/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9902 - loss: 0.0838\n",
      "Epoch 12: val_loss did not improve from 0.86650\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9902 - loss: 0.0839 - val_accuracy: 0.5864 - val_loss: 2.1373\n",
      "Epoch 13/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9940 - loss: 0.0793\n",
      "Epoch 13: val_loss improved from 0.86650 to 0.14916, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9939 - loss: 0.0795 - val_accuracy: 0.9761 - val_loss: 0.1492\n",
      "Epoch 14/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9862 - loss: 0.0940\n",
      "Epoch 14: val_loss did not improve from 0.14916\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.9864 - loss: 0.0937 - val_accuracy: 0.8447 - val_loss: 0.6403\n",
      "Epoch 15/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0722\n",
      "Epoch 15: val_loss did not improve from 0.14916\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0721 - val_accuracy: 0.7840 - val_loss: 1.0363\n",
      "Epoch 16/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9912 - loss: 0.0804\n",
      "Epoch 16: val_loss improved from 0.14916 to 0.07103, saving model to model_attn_dropouts.keras\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9912 - loss: 0.0805 - val_accuracy: 0.9963 - val_loss: 0.0710\n",
      "Epoch 17/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9984 - loss: 0.0672\n",
      "Epoch 17: val_loss did not improve from 0.07103\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9983 - loss: 0.0672 - val_accuracy: 0.9007 - val_loss: 0.3664\n",
      "Epoch 18/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9909 - loss: 0.0821\n",
      "Epoch 18: val_loss did not improve from 0.07103\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9907 - loss: 0.0825 - val_accuracy: 0.5055 - val_loss: 4.0533\n",
      "Epoch 19/30\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9908 - loss: 0.0863\n",
      "Epoch 19: val_loss did not improve from 0.07103\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.9908 - loss: 0.0861 - val_accuracy: 0.9908 - val_loss: 0.0804\n",
      "training time exceeded and ending early\n",
      "training ended on epoch 19\n",
      "training time = 20.173015399773917 mins\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "Time Took to Train: 1210.4030938148499\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Train the model with both callbacks\n",
    "\n",
    "small.compile(\n",
    "    optimizer='adam',\n",
    "    loss = {\n",
    "        'output': 'binary_crossentropy',\n",
    "    },\n",
    "    #loss_weights = loss_weights,\n",
    "    metrics = {\n",
    "        'output': 'accuracy'\n",
    "    })\n",
    "\n",
    "start_time = time.time()\n",
    "history = small.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=30,\n",
    "    batch_size=32,                       \n",
    "    verbose=True,\n",
    "    callbacks=[checkpoint, TrainForTime(train_time),early_stopping]\n",
    ")\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Time Took to Train: {training_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f29319-30b1-4b11-b795-a56eacdacd73",
   "metadata": {},
   "source": [
    "## Testing Performance Using Test Set\n",
    "- Ensure we test inference time\n",
    "- Training Time\n",
    "- Binary classification we can use confusion matrix\n",
    "- F1, precision, recall and accuracy\n",
    "- We also need to find the EER as this is a popular metric in biometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e335ef72-81cc-4c57-9bff-f9a011ff7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def compute_eer(y_true, y_scores):\n",
    "    # y_true: binary labels (0 for negative, 1 for positive)\n",
    "    # y_scores: model’s positive-class scores (probabilities, logits, etc.)\n",
    "\n",
    "    # 1) Compute FPR, TPR at all thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "\n",
    "    # 2) Compute FRR = 1 - TPR\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # 3) Find the threshold where |FPR - FNR| is minimal\n",
    "    idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    eer = (fpr[idx] + fnr[idx]) / 2  # you can average or just take fpr[idx]\n",
    "\n",
    "    return eer, thresholds[idx]\n",
    "        \n",
    "def evaluate_model(model_path, train_ds, test_ds, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Loads a Keras model, evaluates on the train and test datasets, \n",
    "    prints confusion matrices and metrics, and reports inference time.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Helper to extract features and labels from a tf.data.Dataset\n",
    "    def unpack_dataset(dataset):\n",
    "        X_list, y_list = [], []\n",
    "        for x_batch, y_batch in dataset:\n",
    "            X_list.append(x_batch.numpy())\n",
    "            y_list.append(y_batch.numpy())\n",
    "        X = np.concatenate(X_list, axis=0)\n",
    "        y = np.concatenate(y_list, axis=0).flatten()\n",
    "        return X, y\n",
    "\n",
    "    # Unpack train and test datasets\n",
    "    X_train, y_train = unpack_dataset(train_ds)\n",
    "    X_test, y_test = unpack_dataset(test_ds)\n",
    "\n",
    "    # Measure inference time on test set\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    y_test_probs = model.predict(X_test, verbose=0)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_train_pred = (model.predict(X_train) >= threshold).astype(int).flatten()\n",
    "    y_test_pred  = (y_test_probs.flatten() >= threshold).astype(int)\n",
    "\n",
    "    # Compute metrics\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)\n",
    "    report_test = classification_report(y_test, y_test_pred, digits=4)\n",
    "\n",
    "    # Print test set metrics\n",
    "    print(f\"Accuracy on test set: {acc_test:.4f}\")\n",
    "    print(\"\\nClassification Report (Test):\")\n",
    "    print(report_test)\n",
    "    print(f\"Inference Time (total): {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Inference Time (per sample): {(end_time - start_time)/len(y_test):.6f} seconds\")\n",
    "\n",
    "    # Plot confusion matrices side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_train, y_train_pred, normalize='true', ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_title(f'Train Confusion Matrix\\nAccuracy: {accuracy_score(y_train, y_train_pred):.4f}')\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_test_pred, normalize='true', ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_title(f'Test Confusion Matrix\\nAccuracy: {acc_test:.4f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    eer, eer_threshold = compute_eer(y_test,y_test_probs)\n",
    "    print(f\"EER = {eer*100:.2f}% at threshold {eer_threshold:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c256fa3a-6b2e-46d7-82d6-7d060db4350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step\n",
      "Accuracy on test set: 0.9678\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9722    0.9632    0.9677       544\n",
      "           1     0.9636    0.9724    0.9680       544\n",
      "\n",
      "    accuracy                         0.9678      1088\n",
      "   macro avg     0.9679    0.9678    0.9678      1088\n",
      "weighted avg     0.9679    0.9678    0.9678      1088\n",
      "\n",
      "Inference Time (total): 1.9692 seconds\n",
      "Inference Time (per sample): 0.001810 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER = 2.85% at threshold 0.595\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('model_attn.keras', train_ds, test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
